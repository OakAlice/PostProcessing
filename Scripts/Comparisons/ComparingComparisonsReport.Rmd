---
title: "ComparingComparisonsReport"
output: html_document
date: "`r Sys.Date()`"
params:
  base_path: "C:/Users/oaw001/OneDrive - University of the Sunshine Coast/PostProcessing"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.width = 8, fig.height = 5)
```

This is the report to compare the comparisons between the species datasets.

Step 1 is to pull together all the data. 
```{r bind, include = FALSE}
files <- list.files(file.path(base_path, "Output"), pattern = "all_smoothed_metrics.csv", full.names = TRUE, recursive = TRUE)

data <- lapply(files, function(x){
  data <- fread(x)
  data$Species <- basename(dirname(x))
  return(data)
})

data <- bind_rows(data)
data <- data %>% filter(Activity == "Macro-Average")

# add levels so its easier to plot later
data$smoothing_type <- factor(data$smoothing_type, levels = c("NoSmoothing", "ModeSmoothing", "DurationSmoothing", "ConfusionSmoothing", "TransitionSmoothing", "HMMSmoothing", "BayesianSmoothing", "KalmanSmoothing", "LSTMSmoothing"))

data$Species <- factor(data$Species, levels = c(unique(data$Species)))

```
```{r}
# save this
print(head(data %>% filter(Metric == "F1")))
fwrite(data, file.path(base_path, "Output", "collated_performance.csv"))
```

Step 2 is to compare these results. 
```{r compare}
# its hard to make any one single judgement, so I can make a plot for now

# Plot so that control is more obvious
df <- data %>% filter(Activity == "Macro-Average", Metric == "F1")
ggplot(df, aes(x = Species, y = Score, fill = smoothing_type)) +
  geom_point(
    data = df[df$smoothing_type != "NoSmoothing", ],
    aes(x = Species, y = Score, fill = smoothing_type),
    shape = 21,
    colour = "white",
    size = 3
  ) +
  geom_point(
    data = df[df$smoothing_type == "NoSmoothing", ],
    aes(x = Species, y = Score),
    shape = 8,
    colour = "black",
    size = 3
  ) +
  my_theme() +
  scale_fill_manual(values = my_colours) +
  labs(x = "Activity", y = "Score", fill = "Smoothing Type") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


# and also do it as relative from the control
setDT(df)

# Get NoSmoothing scores by Species
baseline <- df[smoothing_type == "NoSmoothing", .(Species, baseline = Score)]
df <- merge(df, baseline, by = "Species", all.x = TRUE)
# Calculate relative change from NoSmoothing
df[, relative_change := Score - baseline]

# now plot that
ggplot(df, aes(x = Species, y = relative_change, fill = smoothing_type)) +
  geom_point(
    data = df[df$smoothing_type != "NoSmoothing", ],
    aes(x = Species, y = relative_change, fill = smoothing_type),
    shape = 21,
    colour = "white",
    size = 3
  ) +
  geom_point(
    data = df[df$smoothing_type == "NoSmoothing", ],
    aes(x = Species, y = relative_change),
    shape = 8,
    colour = "black",
    size = 3
  ) +
  my_theme() +
  scale_fill_manual(values = my_colours) +
  labs(x = "Activity", y = "Relative change to F1 Score", fill = "Smoothing Type") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Step 3 is to correlate this with the sequential stats I was able to draw out in the sequence report on the training data.

```{r extracting stat data}
stat_files <- list.files(file.path(base_path, "Output"), pattern = "Sequence_stats.csv", full.names = TRUE, recursive = TRUE)

stat_data <- lapply(stat_files, function(x){
  data <- fread(x)
  return(data)
})

stat_data <- bind_rows(stat_data)
head(stat_data)
```

Of these stats, the ones I think will be most predictive are Prop_Transitions (which represents how many of the training sequences contained transitions) and Transition_Rate (which is how quickly the behaviours turnover within those sequences).

Firstly I just look att the change to relative performance.

```{r}
# add the 2 information sources together
full_df <- merge(df, stat_data, by = "Species")

fwrite(full_df, file.path(base_path, "Output", "relative_change_full_df.csv"))

simple_model <- lmer(relative_change ~ smoothing_type + (1|Species), data = full_df)
summary(simple_model)
```



Then I look at the effect of transitions in the data and test whether there were interaction effects by doing an anova comparing the predictive performance of the model with and without the interactions.

```{r some stats}

# model_minimum <- lm(relative_change ~ smoothing_type + Transition_Rate + Prop_Transitions + Species, data = full_df)

model_minimal <- lmer(relative_change ~ smoothing_type + Transition_Rate +
                   (1|Species), data = full_df, REML = FALSE)

model_med <- lmer(relative_change ~ smoothing_type + Transition_Rate + 
                   smoothing_type:Transition_Rate +
                   (1|Species), data = full_df, REML = FALSE)

model_full <- lmer(relative_change ~ smoothing_type * Transition_Rate + 
                   (1|Species), data = full_df, REML = FALSE)

anova(model_minimal, model_med, model_full)
```

Full model was significantly better, so I will use it.

```{r}
summary(model_full)
```
