==just some notes to show where my thinking is going==
# Discussion
In this study, we compared the effect of seven post-processing techniques on the classification performance of accelerometer-based behavioural classification predictions. 

**Base performance**
- The base, control, classification differed in performance between species between 0.2-0.7 weighted-average F1-score. 
- Studd_Squirrel dataset did the worst (likely because of lowest sample rate) and the Sparkes_Koala did the best (probably because it was validated differently to the remainder datasets and thus had a significant advantage). 
- Performance within the other datasets would have been dependent on various factors such as volume of data, number of classes (affecting random baseline), and the distinctiveness between the class boundaries --- variables that are all beyond the scope of this study.

**Effect of post-processing**
- Naive Bayes and Duration-based smoothing were both found to produce significant improvements in the classification performance (ranging from 0.01 to 0.4 improvement). Mode-based, Transition, and HMM had marginal effects close to significance. 
- This suggests that inclusion of a post-processing method will improve performance, but differently for each dataset. Worth playing around with your datasets strengths and weaknesses to see which of the post-processing methods are best for your data.

**Impact on training transitions on post-processing**
- When accounting for transition rate and proportion of sequences with transitions, HMM and LSTM methods had a significantly negative effect. HMM improved significantly with increased transition rate and proportion of transitions, but there was also a three way interaction with a negative effect suggesting that HMM is helpful in dynamic sequences with rapid transitions.
- However, when you just use the transition rate,  there's a significant positive interaction between LSTM Smoothing and transition rate, with a marginal effect of transition rate on Transition Smoothing.
- I find it very weird that Bayesian Smoothing isn't affected by the transition rate...?
- A limitation for all post-processing methods that learn from natural sequences in the training data however is that they rely on those natural sequences being represented in the training data. That is, these methods will only present improvements when the training data represents long continuous stretches of behaviour, containing multiple natural transitions. While some studies collect behaviour in this way, it is not true of all studies. In the koala data used in this study, for example, training data was not collected in sequence but as isolated representative snippets. More than 90% of sequences in the training data contained only 1 behaviour, with 2 behaviours in only very small minority. Thus, there were very few transitions for the models to learn from, providing such limited information that the higher-order post-processing methods failed to confer advantages over the most basic modal smoothing. Given that several of the models had interactions with the metrics of continuousness, it may explain why these models could not effectively learn from the data.

**Meaning of the study**
By incorporating higher-level inference, and utilising the sequential information available in time-series data, we are able to achieve higher classification performance without needing perfect classification accuracy during the ML prediction stage. In light of this performance gain, as a research community, we must now ask whether the substantial effort required to marginally improve classification model performance is still necessary, particularly given that simpler post-processing steps enable similar gains. Enhancing a model often demands significant resources such as collecting new data from rare behaviours or additional individuals, computationally expensive  hyper-parameter tuning, and careful balancing of model power against over-fitting. In contrast, post-processing methods can be readily applied to existing model outputs, using the data already available. 

Furthermore, in many ecological studies, the objective is not to capture behaviour at the finest temporal resolution, but to reveal broader patterns of activity. These coarse-scale trends are typically robust to local misclassifications and may not require high-fidelity predictions at every time step, so long as the outputs reflect meaningful ecological processes. Thus, given that perfection is neither possible nor necessary, a more parsimonious, easily implemented, and interpreted result is suggested in post-processing.

**Recommendations**
- In future, we should aim to collect more natural training data representative of true sequences of behaviour and including the transitions that we will be modelling out in reality.
- Design a perfect smoother by incorporating detailed ecological knowledge about plausible sequences and meaningful duration.
- This study is a first exploratory step into the possibility of incorporating ecological knowledge into the way we design and deploy these models. We hope to inspire others to consider the potential for this approach.