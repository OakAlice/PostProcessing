==Results aren't complete because some of the datasets are still processing but I've put in very basic general information indicating trends so far and the vibe of analysis I've gone for==
### Relative Performance Changes
The performance of the base classifier with no post-processing (control) differed between species with a range 0.2-0.7 weighted-average F1-score. Each post-processing method had a differing effect on each of the species. The unique characteristics of each dataset make their performance challenging to compare to each other, but considering only the relative differences between the post-processed performance and control method, some trends can be observed.

![[Pasted image 20250702120659.png|700]]
***Figure 2.** Relative change in weighted-average F1-Score for each dataset and post-processing method. Star symbols represent the performance of the base-classifier with no post-processing (control) --- set to 0 as the baseline. Colours represent performance of each trialled post-processing method as a relative change from the performance of the control.*

Firstly, a linear mixed-effects model was used to assess the effects of post-processing method on the relative change in classification performance, with Species included as a random effect. Naive Bayes post-processing was found to have  a strong positive effect (β = 0.313, SE = 0.098, t(53) = 3.21, p = 0.002) as did Duration-based post-processing (β = 0.259, SE = 0.101, t(53) = 2.56, p = 0.013). Other methods such as Mode-based, Transition, and HMM Post-processing showed marginal effects (p = 0.056–0.080) while Confusion and LSTM methods did not significantly change from the control.

To assess the effect of the continuousness of recording in the training data, these covariates were added to the model. Firstly, the importance of the interactions between the three predictor variables (post-processing type, proportion of sequences that included transitions, and the rate of transitions) was assessed by comparing three models: minimal with no interactions, medium with all 2-way interactions, and a full model with three-way interactions. The medium and full model were found to both be significantly better at explaining the variance in the model than the minimal model, and thus the full model was used. This full model found multiple significant effects.

When accounting for transition rate and proportion of sequences with transitions, HMM and LSTM methods had a significantly negative effect on performance (_β_ = –0.445, _SE_ = 0.151, _t_ = –2.95, _p_ = 0.0045 and _β_ = –0.344, _SE_ = 0.150, _t_ = –2.29, _p_ = 0.0255, respectively). However, the performance of HMM improved significantly with increased transition rate (_β_ = 14.86, _p_ = 0.0063) and proportion of transitions (_β_ = 0.898, _p_ = 0.0033). There was also a three way interaction, though, with a negative effect (_β_ = –24.31, _SE_ = 6.80, _t_ = –3.57, _p_ = 0.0007)
### Changes to Ecological Interpretation
==have only done this for 1 individual from 1 dataset just due to processing time and my desktop being busy with other stuff but its still proof of theory ==
![[Pasted image 20250619210043.png|700]]
